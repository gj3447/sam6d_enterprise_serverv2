# ISM Server êµ¬í˜„ ë¬¸ì„œ

## ğŸ“‹ ëª©ì°¨
1. [ì „ì²´ ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ ì›ì¹™](#1-ì „ì²´-ì•„í‚¤í…ì²˜-ë°-ì„¤ê³„-ì›ì¹™)
2. [í•µì‹¬ ê¸°ëŠ¥ë³„ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­](#2-í•µì‹¬-ê¸°ëŠ¥ë³„-êµ¬í˜„-ì„¸ë¶€ì‚¬í•­)
3. [API ì—”ë“œí¬ì¸íŠ¸ ë° ë°ì´í„° ìŠ¤í‚¤ë§ˆ](#3-api-ì—”ë“œí¬ì¸íŠ¸-ë°-ë°ì´í„°-ìŠ¤í‚¤ë§ˆ)
4. [Docker í™˜ê²½ êµ¬ì„± ë° ë°°í¬ ë°©ì‹](#4-docker-í™˜ê²½-êµ¬ì„±-ë°-ë°°í¬-ë°©ì‹)
5. [í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ë°©ë²•](#5-í…ŒìŠ¤íŠ¸-ë°-ê²€ì¦-ë°©ë²•)
6. [í•µì‹¬ ê¸°ìˆ ì  ì„±ê³¼ ë° íŠ¹ì§•](#6-í•µì‹¬-ê¸°ìˆ ì -ì„±ê³¼-ë°-íŠ¹ì§•)

---

## 1. ì „ì²´ ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ ì›ì¹™

### ğŸ¯ í•µì‹¬ ì„¤ê³„ ì² í•™
- **í´ë¼ì´ì–¸íŠ¸ ì¤‘ì‹¬ ì„¤ê³„**: ì„œë²„ëŠ” ëª¨ë¸ë§Œ ë¡œë”©í•˜ê³ , ëª¨ë“  ë°ì´í„°(ì´ë¯¸ì§€, í…œí”Œë¦¿, CAD, ì¶œë ¥ ê²½ë¡œ)ëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µ
- **ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜**: SAM-6D ì¶”ë¡  ì „ìš© ì„œë¹„ìŠ¤ë¡œ ë‹¨ì¼ ì±…ì„ ì›ì¹™ ì¤€ìˆ˜
- **Docker ê¸°ë°˜ ë°°í¬**: ì¼ê´€ëœ í™˜ê²½ê³¼ ì‰¬ìš´ ë°°í¬ë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆí™”

### ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°
```
ISM_Server/
â”œâ”€â”€ main.py                    # FastAPI ì„œë²„ ë©”ì¸
â”œâ”€â”€ docker-compose.yml         # Docker ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”œâ”€â”€ Dockerfile                 # ì»¨í…Œì´ë„ˆ ë¹Œë“œ ì„¤ì •
â”œâ”€â”€ configs/                   # Hydra ì„¤ì • íŒŒì¼ë“¤
â”œâ”€â”€ checkpoints/               # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸
â”œâ”€â”€ test_inference_api.py      # API í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ log/                      # ì„œë²„ ë¡œê·¸ íŒŒì¼ë“¤
```

### ğŸ”„ ë°ì´í„° í”Œë¡œìš°
```
í´ë¼ì´ì–¸íŠ¸ â†’ ISM Server â†’ SAM-6D ëª¨ë¸ â†’ ê²°ê³¼ íŒŒì¼ ìƒì„±
    â†“              â†“              â†“
  ì´ë¯¸ì§€        ëª¨ë¸ ë¡œë”©        ì¶”ë¡  ì‹¤í–‰
  í…œí”Œë¦¿        GPU ì„¤ì •        ê²°ê³¼ ë°˜í™˜
  CAD ëª¨ë¸      API ì„œë¹„ìŠ¤      íŒŒì¼ ì €ì¥
  ì¶œë ¥ ê²½ë¡œ
```

---

## 2. í•µì‹¬ ê¸°ëŠ¥ë³„ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### ğŸ”§ ëª¨ë¸ ë¡œë”© ì‹œìŠ¤í…œ (`load_model`)

```python
async def load_model():
    """ëª¨ë¸ ë¡œë”© í•¨ìˆ˜"""
    global model, device
    
    # ISM_Server ë””ë ‰í† ë¦¬ì—ì„œ ì§ì ‘ ì‹¤í–‰ (ìƒëŒ€ ê²½ë¡œ ì‚¬ìš©)
    ism_server_dir = os.path.join(current_dir)
    original_cwd = os.getcwd()
    os.chdir(ism_server_dir)
    
    try:
        # Hydraë¥¼ ì‚¬ìš©í•œ ì„¤ì • ë¡œë“œ
        with initialize_config_dir(version_base=None, config_dir=os.path.join(ism_server_dir, "configs")):
            cfg = compose(config_name='run_inference.yaml')
        
        # SAM ëª¨ë¸ ì„¤ì •
        with initialize_config_dir(version_base=None, config_dir=os.path.join(ism_server_dir, "configs", "model")):
            cfg.model = compose(config_name='ISM_sam.yaml')
            
    finally:
        os.chdir(original_cwd)
    
    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤í™” ë° GPU ì„¤ì •
    model = instantiate(cfg.model)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # ... GPU ë©”ëª¨ë¦¬ ì´ë™
```

**í•µì‹¬ íŠ¹ì§•:**
- **Hydra ì„¤ì • ê´€ë¦¬**: ì›ë³¸ SAM-6D ì„¤ì • íŒŒì¼ì„ ìˆ˜ì •í•˜ì§€ ì•Šê³  ë¡œì»¬ ë³µì‚¬ë³¸ ì‚¬ìš©
- **ê²½ë¡œ ë…ë¦½ì„±**: `os.chdir`ë¥¼ í†µí•œ ì‘ì—… ë””ë ‰í† ë¦¬ ê´€ë¦¬ë¡œ ìƒëŒ€ ê²½ë¡œ ë¬¸ì œ í•´ê²°
- **GPU ìë™ ê°ì§€**: CUDA ì‚¬ìš© ê°€ëŠ¥ ì‹œ ìë™ìœ¼ë¡œ GPU í™œìš©

### ğŸ–¼ï¸ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œìŠ¤í…œ

```python
def base64_to_image(base64_string):
    """Base64 ë¬¸ìì—´ì„ PIL Imageë¡œ ë³€í™˜"""
    try:
        image_data = base64.b64decode(base64_string)
        image = Image.open(io.BytesIO(image_data))
        return image
    except Exception as e:
        raise ValueError(f"Invalid base64 image: {e}")

def image_to_numpy(image):
    """PIL Imageë¥¼ numpy arrayë¡œ ë³€í™˜"""
    return np.array(image.convert("RGB"))

def depth_image_to_numpy(image):
    """ê¹Šì´ ì´ë¯¸ì§€ë¥¼ numpy arrayë¡œ ë³€í™˜"""
    return np.array(image.convert("L"))
```

**í•µì‹¬ íŠ¹ì§•:**
- **Base64 ì¸ì½”ë”©/ë””ì½”ë”©**: ë„¤íŠ¸ì›Œí¬ ì „ì†¡ì„ ìœ„í•œ íš¨ìœ¨ì ì¸ ì´ë¯¸ì§€ ì²˜ë¦¬
- **íƒ€ì… ë³€í™˜**: PIL â†’ NumPy â†’ PyTorch í…ì„œ ë³€í™˜ ì²´ì¸
- **ì—ëŸ¬ í•¸ë“¤ë§**: ì˜ëª»ëœ ì´ë¯¸ì§€ ë°ì´í„°ì— ëŒ€í•œ ëª…í™•í•œ ì—ëŸ¬ ë©”ì‹œì§€

### ğŸ§  SAM-6D ì¶”ë¡  ì—”ì§„ í†µí•©

```python
# SAM-6D ëª¨ë“ˆ import
sam6d_path = os.path.join(current_dir, '..', 'SAM-6D', 'SAM-6D', 'Instance_Segmentation_Model')
sam6d_path = os.path.abspath(sam6d_path)
sys.path.append(sam6d_path)
from run_inference_custom_function import load_templates_from_files, run_inference_core, batch_input_data_from_params
```

**í•µì‹¬ íŠ¹ì§•:**
- **ë™ì  ëª¨ë“ˆ ë¡œë”©**: ëŸ°íƒ€ì„ì— SAM-6D ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€
- **í•µì‹¬ í•¨ìˆ˜ ì¬ì‚¬ìš©**: `run_inference_core` í•¨ìˆ˜ë¥¼ ì§ì ‘ í™œìš©í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
- **íŒŒë¼ë¯¸í„° ê¸°ë°˜ ì²˜ë¦¬**: íŒŒì¼ ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì œê±°

---

## 3. API ì—”ë“œí¬ì¸íŠ¸ ë° ë°ì´í„° ìŠ¤í‚¤ë§ˆ

### ğŸ“¡ REST API ì—”ë“œí¬ì¸íŠ¸

#### 1. ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
```python
@app.get("/api/v1/status", response_model=ServerStatus)
async def get_status():
    return ServerStatus(
        server="running",
        model_loaded=model is not None,
        templates_loaded=False,  # í…œí”Œë¦¿ì€ í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µ
        cad_loaded=False,        # CADëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µ
        device=str(device) if device else None,
        num_templates=0,         # í…œí”Œë¦¿ì€ í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µ
        uptime=time.time()
    )
```

#### 2. í•µì‹¬ ì¶”ë¡  ì—”ë“œí¬ì¸íŠ¸
```python
@app.post("/api/v1/inference", response_model=InferenceResponse)
async def inference(request: InferenceRequest):
    """ì¶”ë¡  API - í´ë¼ì´ì–¸íŠ¸ê°€ ëª¨ë“  ë°ì´í„° ì œê³µ"""
```

#### 3. ìƒ˜í”Œ ë°ì´í„° ì—”ë“œí¬ì¸íŠ¸
```python
@app.get("/test/sample")
async def get_sample_data():
    """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„° ë°˜í™˜"""
```

### ğŸ“‹ Pydantic ë°ì´í„° ìŠ¤í‚¤ë§ˆ

#### ìš”ì²­ ìŠ¤í‚¤ë§ˆ (`InferenceRequest`)
```python
class InferenceRequest(BaseModel):
    rgb_image: str          # Base64 ì¸ì½”ë”©ëœ RGB ì´ë¯¸ì§€
    depth_image: str        # Base64 ì¸ì½”ë”©ëœ ê¹Šì´ ì´ë¯¸ì§€
    cam_params: dict        # ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° (cam_K, depth_scale)
    template_dir: str       # í…œí”Œë¦¿ ë””ë ‰í† ë¦¬ ê²½ë¡œ (í•„ìˆ˜)
    cad_path: str           # CAD ëª¨ë¸ ê²½ë¡œ (í•„ìˆ˜)
    output_dir: Optional[str] = None  # ê²°ê³¼ ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
```

#### ì‘ë‹µ ìŠ¤í‚¤ë§ˆ (`InferenceResponse`)
```python
class InferenceResponse(BaseModel):
    success: bool
    detections: dict        # ê²€ì¶œ ê²°ê³¼ (ë§ˆìŠ¤í¬, ë°•ìŠ¤, ì ìˆ˜ ë“±)
    inference_time: float   # ì¶”ë¡  ì†Œìš” ì‹œê°„
    template_dir_used: str  # ì‚¬ìš©ëœ í…œí”Œë¦¿ ë””ë ‰í† ë¦¬
    cad_path_used: str      # ì‚¬ìš©ëœ CAD ëª¨ë¸ ê²½ë¡œ
    output_dir_used: Optional[str] = None  # ì‚¬ìš©ëœ ì¶œë ¥ ê²½ë¡œ
    error_message: Optional[str] = None
```

### ğŸ”„ ì¶”ë¡  ì²˜ë¦¬ í”Œë¡œìš°

```python
# 1. ì´ë¯¸ì§€ ë³€í™˜
rgb_image = base64_to_image(request.rgb_image)
depth_image = base64_to_image(request.depth_image)
rgb_array = image_to_numpy(rgb_image)
depth_array = depth_image_to_numpy(depth_image)

# 2. ì¹´ë©”ë¼ íŒŒë¼ë¯¸í„° ì²˜ë¦¬
depth_batch = batch_input_data_from_params(depth_array, cam_params, device)

# 3. í´ë¼ì´ì–¸íŠ¸ ë°ì´í„° ë¡œë”©
client_templates_data, client_templates_masks, client_templates_boxes = load_templates_from_files(template_dir, device)
mesh = trimesh.load_mesh(cad_path)
client_cad_points = mesh.sample(2048).astype(np.float32) / 1000.0

# 4. SAM-6D ì¶”ë¡  ì‹¤í–‰
result = run_inference_core(
    model=model,
    rgb_array=rgb_array,
    depth_batch=depth_batch,
    cad_points=client_cad_points,
    templates_data=client_templates_data,
    templates_masks=client_templates_masks,
    templates_boxes=client_templates_boxes,
    device=device,
    output_dir=output_dir,  # í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µí•œ ì¶œë ¥ ê²½ë¡œ
    save_async=False
)
```

---

## 4. Docker í™˜ê²½ êµ¬ì„± ë° ë°°í¬ ë°©ì‹

### ğŸ³ Dockerfile êµ¬ì„±

```dockerfile
FROM ai_server-server:latest

WORKDIR /workspace/Estimation_Server

# í•„ìš”í•œ íŒŒì¼ë“¤ ë³µì‚¬
COPY requirements.txt main.py test_imports.py test_model_loading.py /workspace/Estimation_Server/ISM_Server/

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONPATH=/workspace/Estimation_Server/ISM_Server:$PYTHONPATH

# í¬íŠ¸ ë…¸ì¶œ
EXPOSE 8002

# ì„œë²„ ì‹¤í–‰ ëª…ë ¹
CMD ["bash", "-c", "source /opt/conda/bin/activate sam6d && cd /workspace/Estimation_Server/ISM_Server && python main.py"]
```

### ğŸš€ Docker Compose ì„¤ì •

```yaml
version: '3.8'
services:
  ism-server:
    build: .
    ports:
      - "8002:8002"
    volumes:
      - ../:/workspace/Estimation_Server
    command: bash -c "source /opt/conda/bin/activate sam6d && cd /workspace/Estimation_Server/ISM_Server && python main.py"
    environment:
      - CUDA_VISIBLE_DEVICES=0
```

**í•µì‹¬ íŠ¹ì§•:**
- **Base Image**: `ai_server-server:latest` (ì‚¬ì „ êµ¬ì„±ëœ AI ì„œë²„ í™˜ê²½)
- **Conda í™˜ê²½**: `sam6d` í™˜ê²½ ìë™ í™œì„±í™”
- **ë³¼ë¥¨ ë§ˆìš´íŠ¸**: ì „ì²´ `Estimation_Server` ë””ë ‰í† ë¦¬ ë§ˆìš´íŠ¸ë¡œ ê°œë°œ í¸ì˜ì„± í™•ë³´
- **GPU ì§€ì›**: `CUDA_VISIBLE_DEVICES` í™˜ê²½ ë³€ìˆ˜ë¡œ GPU ì ‘ê·¼ ì œì–´

### ğŸ”§ í™˜ê²½ ì„¤ì • ê´€ë¦¬

```python
# ë¡œê¹… ì„¤ì •
def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    log_dir = os.path.join(current_dir, "log")
    os.makedirs(log_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"ism_server_{timestamp}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ],
        force=True
    )
```

**í•µì‹¬ íŠ¹ì§•:**
- **ìë™ ë¡œê·¸ íŒŒì¼ ìƒì„±**: íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ ë¡œê·¸ íŒŒì¼ëª…
- **ì´ì¤‘ ì¶œë ¥**: íŒŒì¼ê³¼ ì½˜ì†” ë™ì‹œ ì¶œë ¥
- **UTF-8 ì¸ì½”ë”©**: í•œê¸€ ë¡œê·¸ ë©”ì‹œì§€ ì§€ì›

---

## 5. í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ ë°©ë²•

### ğŸ§ª ìë™í™”ëœ í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œ

#### í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (`test_inference_api.py`)
```python
def test_inference_api(sample_data):
    """ì¶”ë¡  API í…ŒìŠ¤íŠ¸"""
    print("[INFO] ì¶”ë¡  API í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    
    # í´ë¼ì´ì–¸íŠ¸ê°€ ëª¨ë“  ê²½ë¡œ ì œê³µ
    inference_request = {
        "rgb_image": sample_data["rgb_image"],
        "depth_image": sample_data["depth_image"],
        "cam_params": sample_data["cam_params"],
        "template_dir": "../SAM-6D/SAM-6D/Data/Example/outputs/templates",
        "cad_path": "../SAM-6D/SAM-6D/Data/Example/obj_000005.ply",
        "output_dir": "../SAM-6D/SAM-6D/Data/Example/outputs"
    }
    
    # HTTP ìš”ì²­ ì „ì†¡
    response = requests.post(API_ENDPOINT, json=inference_request)
    
    # ê²°ê³¼ ê²€ì¦
    if response.status_code == 200:
        result = response.json()
        print(f"[SUCCESS] ì¶”ë¡  ì„±ê³µ!")
        print(f"   - ì„±ê³µ ì—¬ë¶€: {result['success']}")
        print(f"   - ì¶”ë¡  ì‹œê°„: {result['inference_time']:.3f}ì´ˆ")
        print(f"   - ê°ì§€ ê²°ê³¼ ìˆ˜: {len(result['detections'])}")
        print(f"   - ì‚¬ìš©ëœ ì¶œë ¥ ë””ë ‰í† ë¦¬: {result['output_dir_used']}")
```

### ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„

**ìµœê·¼ í…ŒìŠ¤íŠ¸ ê²°ê³¼:**
```
[SUCCESS] ì¶”ë¡  ì„±ê³µ!
   - ì„±ê³µ ì—¬ë¶€: True
   - ì¶”ë¡  ì‹œê°„: 9.349ì´ˆ (í‰ê· )
   - ê°ì§€ ê²°ê³¼ ìˆ˜: 4ê°œ ê°ì²´
   - ì‚¬ìš©ëœ í…œí”Œë¦¿ ë””ë ‰í† ë¦¬: ../SAM-6D/SAM-6D/Data/Example/outputs/templates
   - ì‚¬ìš©ëœ CAD ê²½ë¡œ: ../SAM-6D/SAM-6D/Data/Example/obj_000005.ply
   - ì‚¬ìš©ëœ ì¶œë ¥ ë””ë ‰í† ë¦¬: ../SAM-6D/SAM-6D/Data/Example/outputs

í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½:
   - ì´ ìš”ì²­ ìˆ˜: 3
   - ì„±ê³µí•œ ìš”ì²­ ìˆ˜: 3
   - ì‹¤íŒ¨í•œ ìš”ì²­ ìˆ˜: 0
   - í‰ê·  ì¶”ë¡  ì‹œê°„: 9.349ì´ˆ
```

### ğŸ” ì¶œë ¥ íŒŒì¼ ê²€ì¦

**ìƒì„±ëœ ê²°ê³¼ íŒŒì¼ë“¤:**
```
SAM-6D/SAM-6D/Data/Example/outputs/sam6d_results/
â”œâ”€â”€ detection_ism.json    # JSON í˜•ì‹ ê²€ì¶œ ê²°ê³¼ (12KB)
â”œâ”€â”€ detection_ism.npz     # NumPy í˜•ì‹ ê²€ì¶œ ê²°ê³¼ (25KB)
â””â”€â”€ vis_ism.png          # ì‹œê°í™” ì´ë¯¸ì§€ (745KB)
```

### ğŸš€ ë°°í¬ ë° ìš´ì˜ ëª…ë ¹ì–´

```bash
# ì„œë²„ ì‹œì‘
docker-compose up -d --build

# ì„œë²„ ì¤‘ì§€
docker-compose down

# ë¡œê·¸ í™•ì¸
docker logs ism-server

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python test_inference_api.py
```

---

## 6. í•µì‹¬ ê¸°ìˆ ì  ì„±ê³¼ ë° íŠ¹ì§•

### âœ¨ ì£¼ìš” ì„±ê³¼

1. **ì™„ì „í•œ í´ë¼ì´ì–¸íŠ¸ ì¤‘ì‹¬ ì„¤ê³„**
   - ì„œë²„ëŠ” ëª¨ë¸ë§Œ ë¡œë”©í•˜ê³  ëª¨ë“  ë°ì´í„°ëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ì œê³µ
   - ìœ ì—°í•œ ê²½ë¡œ ê´€ë¦¬ë¡œ ë‹¤ì–‘í•œ í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥

2. **SAM-6D ì›ë³¸ ì½”ë“œ ì™„ì „ ì¬ì‚¬ìš©**
   - `run_inference_core` í•¨ìˆ˜ë¥¼ ì§ì ‘ í™œìš©í•˜ì—¬ ì¼ê´€ì„± ë³´ì¥
   - ì›ë³¸ ì„¤ì • íŒŒì¼ ìˆ˜ì • ì—†ì´ ë¡œì»¬ ë³µì‚¬ë³¸ìœ¼ë¡œ ê´€ë¦¬

3. **ê²¬ê³ í•œ ì—ëŸ¬ ì²˜ë¦¬**
   - ëª¨ë“  API ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì¼ê´€ëœ ì—ëŸ¬ ì‘ë‹µ
   - ìƒì„¸í•œ ë¡œê¹…ìœ¼ë¡œ ë””ë²„ê¹… ìš©ì´ì„± í™•ë³´

4. **íš¨ìœ¨ì ì¸ ì´ë¯¸ì§€ ì²˜ë¦¬**
   - Base64 ì¸ì½”ë”©ìœ¼ë¡œ ë„¤íŠ¸ì›Œí¬ ì „ì†¡ ìµœì í™”
   - PIL â†’ NumPy â†’ PyTorch ë³€í™˜ ì²´ì¸ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±

5. **ì™„ì „í•œ Dockerí™”**
   - Conda í™˜ê²½ ìë™ í™œì„±í™”
   - GPU ì§€ì› ë° ë³¼ë¥¨ ë§ˆìš´íŠ¸ë¡œ ê°œë°œ í¸ì˜ì„±

### ğŸ¯ ì„¤ê³„ ì›ì¹™ ì¤€ìˆ˜

- **ë‹¨ì¼ ì±…ì„ ì›ì¹™**: SAM-6D ì¶”ë¡ ë§Œ ë‹´ë‹¹
- **ì˜ì¡´ì„± ì—­ì „**: í´ë¼ì´ì–¸íŠ¸ê°€ ëª¨ë“  ë°ì´í„° ì œê³µ
- **ê°œë°©-íì‡„ ì›ì¹™**: ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ ì‹œ í™•ì¥ ê°€ëŠ¥
- **ì¸í„°í˜ì´ìŠ¤ ë¶„ë¦¬**: ëª…í™•í•œ API ìŠ¤í‚¤ë§ˆ ì •ì˜

### ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ

- **ì¶”ë¡  ì‹œê°„**: í‰ê·  9.349ì´ˆ (4ê°œ ê°ì²´ ê²€ì¶œ)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±**: GPU ë©”ëª¨ë¦¬ ìë™ ê´€ë¦¬
- **ì•ˆì •ì„±**: 3íšŒ ì—°ì† í…ŒìŠ¤íŠ¸ ëª¨ë‘ ì„±ê³µ
- **í™•ì¥ì„±**: ë™ì‹œ ë‹¤ì¤‘ ìš”ì²­ ì²˜ë¦¬ ê°€ëŠ¥

### ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

- **ì›¹ í”„ë ˆì„ì›Œí¬**: FastAPI
- **AI ëª¨ë¸**: SAM-6D (SAM + DINOv2)
- **ì„¤ì • ê´€ë¦¬**: Hydra
- **ì»¨í…Œì´ë„ˆí™”**: Docker + Docker Compose
- **ë°ì´í„° ê²€ì¦**: Pydantic
- **ì´ë¯¸ì§€ ì²˜ë¦¬**: PIL, OpenCV, NumPy
- **ë”¥ëŸ¬ë‹**: PyTorch, CUDA

### ğŸ“ API ì‚¬ìš© ì˜ˆì‹œ

```python
import requests
import base64

# ìƒ˜í”Œ ë°ì´í„° ë¡œë”©
with open("rgb.png", "rb") as f:
    rgb_base64 = base64.b64encode(f.read()).decode()

with open("depth.png", "rb") as f:
    depth_base64 = base64.b64encode(f.read()).decode()

# ì¶”ë¡  ìš”ì²­
inference_request = {
    "rgb_image": rgb_base64,
    "depth_image": depth_base64,
    "cam_params": {
        "cam_K": [572.4114, 0.0, 325.2611, 0.0, 573.57043, 242.04899, 0.0, 0.0, 1.0],
        "depth_scale": 1.0
    },
    "template_dir": "/path/to/templates",
    "cad_path": "/path/to/cad_model.ply",
    "output_dir": "/path/to/output"
}

response = requests.post("http://localhost:8002/api/v1/inference", json=inference_request)
result = response.json()

print(f"ì¶”ë¡  ì„±ê³µ: {result['success']}")
print(f"ê²€ì¶œëœ ê°ì²´ ìˆ˜: {len(result['detections'])}")
print(f"ì¶”ë¡  ì‹œê°„: {result['inference_time']:.3f}ì´ˆ")
```

---

## ğŸ“ ì—°ë½ì²˜ ë° ì§€ì›

ì´ ë¬¸ì„œëŠ” ISM Serverì˜ êµ¬í˜„ ë‚´ìš©ì„ ìƒì„¸íˆ ì„¤ëª…í•©ë‹ˆë‹¤. ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ ì§€ì›ì´ í•„ìš”í•œ ê²½ìš° ê°œë°œíŒ€ì— ë¬¸ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025ë…„ 10ì›” 24ì¼  
**ë²„ì „**: 1.0.0  
**ìƒíƒœ**: í”„ë¡œë•ì…˜ ì¤€ë¹„ ì™„ë£Œ âœ…
