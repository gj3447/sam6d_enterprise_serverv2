# PEM_Server 구현 순서 및 테스트 계획

## 개요
ISM Server와 연동되는 PEM (Pose Estimation Model) 서버를 단계별로 구현하고, 각 단계마다 테스트하면서 버그를 잡아나가는 방식으로 진행합니다.

## 구현 순서

### Phase 0: Docker 환경 및 라이브러리 Import 테스트
**목표**: Docker 환경에서 PEM 모델에 필요한 라이브러리들이 정상적으로 import되는지 확인

#### 0.1 Docker 환경 접속 및 기본 확인
```bash
# Docker 컨테이너 실행 (기존 sam6d 환경 활용)
docker-compose -f docker-compose.sam6d.yml up -d sam6d-server

# 컨테이너 접속
docker exec -it sam6d-server bash

# 작업 디렉토리 확인
pwd
ls -la

# Python 환경 확인
conda activate sam6d
python --version
```

#### 0.2 기본 라이브러리 Import 테스트
```bash
# 컨테이너 내부에서 Python 실행
python

# 기본 라이브러리 테스트
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")

import numpy as np
print(f"NumPy version: {np.__version__}")

from PIL import Image
print("PIL imported successfully")

import trimesh
print("Trimesh imported successfully")

import cv2
print(f"OpenCV version: {cv2.__version__}")

import pycocotools.mask as cocomask
print("pycocotools imported successfully")
```

#### 0.3 PEM 관련 라이브러리 Import 테스트
```bash
# PEM 디렉토리로 이동
cd /workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model

# Python path 설정
export PYTHONPATH="/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model:$PYTHONPATH"

# PEM 관련 라이브러리 테스트
python -c "
import sys
sys.path.append('/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model')

# 데이터 유틸리티 테스트
from utils.data_utils import load_im, get_bbox, get_point_cloud_from_depth
print('PEM data utils imported successfully')

# 그리기 유틸리티 테스트
from utils.draw_utils import draw_detections
print('PEM draw utils imported successfully')

# 모델 유틸리티 테스트
from utils.model_utils import load_model
print('PEM model utils imported successfully')

# 추론 함수 테스트
from run_inference_custom_function import run_inference_core
print('PEM run_inference_custom_function imported successfully')
"
```

#### 0.4 PointNet2 CUDA 확장 테스트
```bash
# PointNet2 디렉토리로 이동
cd /workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/model/pointnet2

# CUDA 확장 모듈 테스트
python -c "
import torch
from pointnet2_modules import PointnetSAModuleMSG
print('PointNet2 CUDA modules imported successfully')

# 간단한 테스트
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f'Using device: {device}')

# PointNet2 모듈 초기화 테스트
sa_module = PointnetSAModuleMSG(
    npoint=512,
    radii=[0.1, 0.2, 0.4],
    nsamples=[16, 32, 128],
    mlps=[[32, 32, 64], [64, 64, 128], [64, 96, 128]],
    use_xyz=True
).to(device)
print('PointNet2 module initialized successfully')
"
```

#### 0.5 FastAPI 라이브러리 설치 및 테스트
```bash
# FastAPI 관련 라이브러리 설치 (이미 설치되어 있을 수 있음)
pip install fastapi uvicorn[standard] pydantic python-multipart

# 설치 확인
python -c "
import fastapi
print(f'FastAPI version: {fastapi.__version__}')

import uvicorn
print('Uvicorn imported successfully')

import pydantic
print(f'Pydantic version: {pydantic.__version__}')
"
```

#### 0.6 성공 기준
- ✅ Docker 컨테이너가 정상적으로 실행됨
- ✅ Python 환경이 정상적으로 설정됨
- ✅ 모든 기본 라이브러리가 정상적으로 import됨
- ✅ PEM 관련 라이브러리가 정상적으로 import됨
- ✅ PointNet2 CUDA 확장 모듈이 정상적으로 동작함
- ✅ FastAPI 라이브러리가 정상적으로 설치되고 import됨

---

### Phase 1: 기본 FastAPI 서버 구현 및 테스트
**목표**: 가장 기본적인 PEM FastAPI 서버가 동작하는지 확인

#### 1.1 Docker 컨테이너 내부에서 기본 파일 생성
```bash
# 컨테이너 내부에서 PEM_Server 디렉토리 생성
mkdir -p /workspace/Estimation_Server/PEM_Server
cd /workspace/Estimation_Server/PEM_Server

# 기본 파일 생성
touch main.py
touch requirements.txt
```

#### 1.2 최소 FastAPI 서버 구현
```python
# main.py
from fastapi import FastAPI

app = FastAPI(title="PEM Server", version="1.0.0")

@app.get("/")
async def root():
    return {"message": "PEM Server is running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "message": "Server is running"}

@app.get("/api/v1/status")
async def get_status():
    return {
        "server": "running",
        "model_loaded": False,
        "device": None,
        "uptime": 0
    }
```

#### 1.3 requirements.txt 생성
```txt
fastapi
uvicorn[standard]
pydantic
python-multipart
torch
torchvision
numpy
opencv-python
PIL
trimesh
pycocotools
```

#### 1.4 Docker 컨테이너 내부에서 테스트
```bash
# 컨테이너 내부에서 서버 실행
cd /workspace/Estimation_Server/PEM_Server
uvicorn main:app --host 0.0.0.0 --port 8003

# 다른 터미널에서 컨테이너 접속하여 테스트
docker exec -it sam6d-server bash
curl http://localhost:8003/
curl http://localhost:8003/health
curl http://localhost:8003/api/v1/status
```

#### 1.5 성공 기준
- ✅ 서버가 정상적으로 시작됨
- ✅ `/` 엔드포인트가 응답함
- ✅ `/health` 엔드포인트가 응답함
- ✅ `/api/v1/status` 엔드포인트가 응답함
- ✅ 에러 없이 서버가 계속 실행됨

---

### Phase 2: PEM 모델 로딩 기능 구현 및 테스트
**목표**: PEM 모델과 관련 데이터를 로딩하는 기능 구현

#### 2.1 필요한 import 추가
```python
# main.py에 추가
import os
import sys
import torch
import torchvision.transforms as transforms
import cv2
import numpy as np
import json
import time
from PIL import Image
import trimesh
import pycocotools.mask as cocomask

# PEM 모듈 경로 추가
sys.path.append('/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model')
sys.path.append('/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/utils')
sys.path.append('/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/model')
sys.path.append('/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/provider')

# PEM 유틸리티 함수 임포트
from utils.data_utils import load_im, get_bbox, get_point_cloud_from_depth, get_resize_rgb_choose
from utils.draw_utils import draw_detections
from utils.model_utils import load_model
from run_inference_custom_function import run_inference_core
```

#### 2.2 전역 변수 및 모델 로딩 함수 추가
```python
# 전역 변수
model = None
device = None

async def load_pem_model():
    """PEM 모델 로딩 함수"""
    global model, device
    
    try:
        # 환경 변수에서 경로 가져오기
        config_path = os.getenv('PEM_CONFIG_PATH', '/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/config/base.yaml')
        checkpoint_path = os.getenv('PEM_CHECKPOINT_PATH', '/workspace/Estimation_Server/SAM-6D/SAM-6D/Pose_Estimation_Model/checkpoints/sam-6d-pem-base.pth')
        
        # GPU 설정
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {device}")
        
        # 모델 로딩 (기존 코드 활용)
        model = load_model(config_path, checkpoint_path, device)
        
        print(f"PEM model loaded successfully on {device}")
        return True
        
    except Exception as e:
        print(f"Error loading PEM model: {e}")
        import traceback
        traceback.print_exc()
        return False
```

#### 2.3 Startup 이벤트 추가
```python
@app.on_event("startup")
async def startup_event():
    """서버 시작 시 PEM 모델 로딩"""
    print("Starting PEM Server...")
    
    # PEM 모델 로딩
    model_loaded = await load_pem_model()
    if not model_loaded:
        print("Failed to load PEM model")
        return
    
    print("PEM model loaded successfully!")
```

#### 2.4 모델 상태 확인 API 업데이트
```python
@app.get("/api/v1/status")
async def get_status():
    """모델 로딩 상태 확인"""
    return {
        "server": "running",
        "model_loaded": model is not None,
        "device": str(device) if device else None,
        "uptime": time.time()
    }
```

#### 2.5 Docker 컨테이너 내부에서 테스트
```bash
# 컨테이너 내부에서 서버 실행
cd /workspace/Estimation_Server/PEM_Server
uvicorn main:app --host 0.0.0.0 --port 8003

# 다른 터미널에서 컨테이너 접속하여 모델 상태 확인
docker exec -it sam6d-server bash
curl http://localhost:8003/api/v1/status
```

#### 2.6 성공 기준
- ✅ 서버 시작 시 PEM 모델이 정상적으로 로딩됨
- ✅ `/api/v1/status` API가 정상적으로 응답함
- ✅ GPU 메모리 사용량이 적절함
- ✅ 모델 로딩 시간이 적절함 (30초 이내)

---

### Phase 3: 포즈 추정 API 구현 및 테스트
**목표**: 실제 포즈 추정 기능을 수행하는 API 구현

#### 3.1 요청/응답 스키마 추가
```python
from pydantic import BaseModel
from typing import Optional, List

class PoseEstimationRequest(BaseModel):
    rgb_image: str              # Base64 인코딩된 RGB 이미지
    depth_image: str            # Base64 인코딩된 깊이 이미지
    cam_params: dict            # 카메라 파라미터 (cam_K, depth_scale)
    detections: dict            # ISM Server 검출 결과
    cad_path: str               # CAD 모델 경로
    output_dir: Optional[str] = None  # 결과 저장 경로 (선택사항)

class PoseResult(BaseModel):
    object_id: int              # 객체 ID
    rotation: List[List[float]] # 3x3 회전 행렬
    translation: List[float]     # 3D 이동 벡터
    confidence: float           # 신뢰도 점수
    bbox: List[int]             # 바운딩 박스 [x, y, w, h]

class PoseEstimationResponse(BaseModel):
    success: bool
    poses: List[PoseResult]
    inference_time: float
    cad_path_used: str
    output_dir_used: Optional[str] = None
    error_message: Optional[str] = None
```

#### 3.2 이미지 처리 함수 추가
```python
import base64
import io

def base64_to_image(base64_string):
    """Base64 문자열을 PIL Image로 변환"""
    try:
        image_data = base64.b64decode(base64_string)
        image = Image.open(io.BytesIO(image_data))
        return image
    except Exception as e:
        raise ValueError(f"Invalid base64 image: {e}")

def image_to_numpy(image):
    """PIL Image를 numpy array로 변환"""
    return np.array(image.convert("RGB"))

def depth_image_to_numpy(image):
    """깊이 이미지를 numpy array로 변환"""
    return np.array(image.convert("L"))
```

#### 3.3 포즈 추정 API 구현
```python
@app.post("/api/v1/pose_estimation", response_model=PoseEstimationResponse)
async def estimate_pose(request: PoseEstimationRequest):
    """포즈 추정 API"""
    start_time = time.time()
    
    try:
        # 입력 검증
        if not model:
            return PoseEstimationResponse(
                success=False,
                poses=[],
                inference_time=0,
                cad_path_used="",
                output_dir_used=None,
                error_message="Model not loaded"
            )
        
        # 이미지 변환
        rgb_image = base64_to_image(request.rgb_image)
        depth_image = base64_to_image(request.depth_image)
        
        rgb_array = image_to_numpy(rgb_image)
        depth_array = depth_image_to_numpy(depth_image)
        
        # 포인트 클라우드 생성
        cam_params = request.cam_params
        point_cloud = get_point_cloud_from_depth(depth_array, cam_params)
        
        # CAD 모델 로딩
        cad_path = request.cad_path
        if not os.path.exists(cad_path):
            return PoseEstimationResponse(
                success=False,
                poses=[],
                inference_time=0,
                cad_path_used=cad_path,
                output_dir_used=None,
                error_message=f"CAD model not found: {cad_path}"
            )
        
        mesh = trimesh.load_mesh(cad_path)
        cad_points = mesh.sample(2048).astype(np.float32) / 1000.0
        
        # 객체별 포즈 추정
        poses = []
        detections = request.detections
        
        for i, mask in enumerate(detections.get('masks', [])):
            try:
                # 객체 마스크 추출
                if isinstance(mask, list):
                    mask = np.array(mask)
                
                # 포인트 클라우드 크롭
                cropped_points = crop_point_cloud_by_mask(point_cloud, mask)
                
                # PEM 모델 추론
                pose_result = run_inference_core(
                    model=model,
                    rgb_array=rgb_array,
                    point_cloud=cropped_points,
                    cad_points=cad_points,
                    device=device
                )
                
                # 결과 변환
                pose = PoseResult(
                    object_id=i,
                    rotation=pose_result['rotation'].tolist(),
                    translation=pose_result['translation'].tolist(),
                    confidence=pose_result['confidence'],
                    bbox=detections.get('boxes', [])[i] if i < len(detections.get('boxes', [])) else [0, 0, 0, 0]
                )
                poses.append(pose)
                
            except Exception as e:
                print(f"Error processing object {i}: {e}")
                continue
        
        inference_time = time.time() - start_time
        
        return PoseEstimationResponse(
            success=True,
            poses=poses,
            inference_time=inference_time,
            cad_path_used=cad_path,
            output_dir_used=request.output_dir,
            error_message=None
        )
        
    except Exception as e:
        inference_time = time.time() - start_time
        return PoseEstimationResponse(
            success=False,
            poses=[],
            inference_time=inference_time,
            cad_path_used="",
            output_dir_used=None,
            error_message=str(e)
        )
```

#### 3.4 포인트 클라우드 처리 함수 추가
```python
def crop_point_cloud_by_mask(point_cloud, mask):
    """마스크를 사용하여 포인트 클라우드 크롭"""
    # 마스크가 있는 영역의 포인트만 추출
    mask_indices = np.where(mask.flatten() > 0)[0]
    
    if len(mask_indices) == 0:
        return np.zeros((1024, 3), dtype=np.float32)
    
    # 포인트 클라우드 크롭
    cropped_points = point_cloud[mask_indices]
    
    # 고정된 크기로 리샘플링 (1024 포인트)
    if len(cropped_points) > 1024:
        indices = np.random.choice(len(cropped_points), 1024, replace=False)
        cropped_points = cropped_points[indices]
    elif len(cropped_points) < 1024:
        # 부족한 포인트는 마지막 포인트로 패딩
        padding = np.tile(cropped_points[-1:], (1024 - len(cropped_points), 1))
        cropped_points = np.vstack([cropped_points, padding])
    
    return cropped_points.astype(np.float32)
```

#### 3.5 테스트용 샘플 데이터 생성
```python
@app.get("/test/sample")
async def get_sample_data():
    """테스트용 샘플 데이터 반환 (ISM 결과 포함)"""
    # 기존 예제 데이터 사용
    rgb_path = "/workspace/Estimation_Server/SAM-6D/SAM-6D/Data/Example/rgb.png"
    depth_path = "/workspace/Estimation_Server/SAM-6D/SAM-6D/Data/Example/depth.png"
    cam_path = "/workspace/Estimation_Server/SAM-6D/SAM-6D/Data/Example/camera.json"
    
    try:
        # 이미지를 Base64로 변환
        with open(rgb_path, "rb") as f:
            rgb_base64 = base64.b64encode(f.read()).decode()
        
        with open(depth_path, "rb") as f:
            depth_base64 = base64.b64encode(f.read()).decode()
        
        # 카메라 파라미터 로딩
        with open(cam_path, "r") as f:
            cam_params = json.load(f)
        
        # 가상의 ISM 검출 결과 생성 (실제로는 ISM Server에서 가져와야 함)
        sample_detections = {
            "masks": [
                [[1, 1, 0, 0], [1, 1, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],  # 첫 번째 객체 마스크
                [[0, 0, 1, 1], [0, 0, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0]]   # 두 번째 객체 마스크
            ],
            "boxes": [[100, 100, 200, 200], [300, 300, 200, 200]],
            "scores": [0.95, 0.87]
        }
        
        return {
            "rgb_image": rgb_base64,
            "depth_image": depth_base64,
            "cam_params": cam_params,
            "detections": sample_detections,
            "cad_path": "/workspace/Estimation_Server/SAM-6D/SAM-6D/Data/Example/obj_000005.ply"
        }
        
    except Exception as e:
        return {"error": str(e)}
```

#### 3.6 Docker 컨테이너 내부에서 테스트
```bash
# 컨테이너 내부에서 서버 실행
cd /workspace/Estimation_Server/PEM_Server
uvicorn main:app --host 0.0.0.0 --port 8003

# 다른 터미널에서 컨테이너 접속하여 테스트
docker exec -it sam6d-server bash

# 샘플 데이터 가져오기
curl http://localhost:8003/test/sample > sample_data.json

# 포즈 추정 테스트
curl -X POST "http://localhost:8003/api/v1/pose_estimation" \
  -H "Content-Type: application/json" \
  -d @sample_data.json
```

#### 3.7 성공 기준
- ✅ 샘플 데이터가 정상적으로 반환됨
- ✅ 포즈 추정 API가 정상적으로 응답함
- ✅ 포즈 추정 결과가 올바른 형식으로 반환됨
- ✅ 추론 시간이 적절함 (5초 이내)
- ✅ 에러 처리가 정상적으로 동작함

---

### Phase 4: ISM Server 연동 및 통합 테스트
**목표**: ISM Server와 PEM Server 간의 연동 테스트

#### 4.1 ISM-PEM 통합 API 구현
```python
@app.post("/api/v1/full_pipeline", response_model=FullPipelineResponse)
async def full_pipeline(request: FullPipelineRequest):
    """ISM + PEM 통합 파이프라인"""
    start_time = time.time()
    
    try:
        # 1. ISM Server 호출 (같은 컨테이너 내부)
        ism_request = {
            "rgb_image": request.rgb_image,
            "depth_image": request.depth_image,
            "cam_params": request.cam_params,
            "template_dir": request.template_dir,
            "cad_path": request.cad_path,
            "output_dir": None  # 파일 저장 안함
        }
        
        # ISM Server 호출
        import requests
        ism_response = requests.post(
            "http://localhost:8002/api/v1/inference",
            json=ism_request,
            timeout=30
        )
        
        if ism_response.status_code != 200:
            return FullPipelineResponse(
                success=False,
                ism_result=None,
                pem_result=None,
                total_time=time.time() - start_time,
                error_message=f"ISM Server error: {ism_response.text}"
            )
        
        ism_result = ism_response.json()
        
        if not ism_result["success"]:
            return FullPipelineResponse(
                success=False,
                ism_result=ism_result,
                pem_result=None,
                total_time=time.time() - start_time,
                error_message=f"ISM inference failed: {ism_result.get('error_message', 'Unknown error')}"
            )
        
        # 2. PEM Server 호출
        pem_request = {
            "rgb_image": request.rgb_image,
            "depth_image": request.depth_image,
            "cam_params": request.cam_params,
            "detections": ism_result["detections"],
            "cad_path": request.cad_path,
            "output_dir": request.output_dir
        }
        
        pem_response = requests.post(
            "http://localhost:8003/api/v1/pose_estimation",
            json=pem_request,
            timeout=30
        )
        
        if pem_response.status_code != 200:
            return FullPipelineResponse(
                success=False,
                ism_result=ism_result,
                pem_result=None,
                total_time=time.time() - start_time,
                error_message=f"PEM Server error: {pem_response.text}"
            )
        
        pem_result = pem_response.json()
        
        total_time = time.time() - start_time
        
        return FullPipelineResponse(
            success=True,
            ism_result=ism_result,
            pem_result=pem_result,
            total_time=total_time,
            error_message=None
        )
        
    except Exception as e:
        total_time = time.time() - start_time
        return FullPipelineResponse(
            success=False,
            ism_result=None,
            pem_result=None,
            total_time=total_time,
            error_message=str(e)
        )
```

#### 4.2 통합 테스트용 스키마 추가
```python
class FullPipelineRequest(BaseModel):
    rgb_image: str              # Base64 인코딩된 RGB 이미지
    depth_image: str            # Base64 인코딩된 깊이 이미지
    cam_params: dict            # 카메라 파라미터
    template_dir: str           # 템플릿 디렉토리 경로
    cad_path: str               # CAD 모델 경로
    output_dir: Optional[str] = None  # 결과 저장 경로

class FullPipelineResponse(BaseModel):
    success: bool
    ism_result: Optional[dict]  # ISM Server 결과
    pem_result: Optional[dict]  # PEM Server 결과
    total_time: float           # 전체 처리 시간
    error_message: Optional[str] = None
```

#### 4.3 통합 테스트 실행
```bash
# ISM Server와 PEM Server 모두 실행
# 터미널 1: ISM Server
cd /workspace/Estimation_Server/ISM_Server
uvicorn main:app --host 0.0.0.0 --port 8002

# 터미널 2: PEM Server
cd /workspace/Estimation_Server/PEM_Server
uvicorn main:app --host 0.0.0.0 --port 8003

# 터미널 3: 통합 테스트
docker exec -it sam6d-server bash

# 샘플 데이터 가져오기
curl http://localhost:8003/test/sample > sample_data.json

# 통합 파이프라인 테스트
curl -X POST "http://localhost:8003/api/v1/full_pipeline" \
  -H "Content-Type: application/json" \
  -d @sample_data.json
```

#### 4.4 성공 기준
- ✅ ISM Server가 정상적으로 응답함
- ✅ PEM Server가 ISM 결과를 정상적으로 처리함
- ✅ 통합 파이프라인이 정상적으로 동작함
- ✅ 전체 처리 시간이 적절함 (15초 이내)
- ✅ 에러 처리가 정상적으로 동작함

---

### Phase 5: Docker Compose 통합 및 최종 테스트
**목표**: Docker Compose를 통해 독립적인 pem-server 서비스로 배포

#### 5.1 Docker Compose 설정 추가
기존 `docker-compose.sam6d.yml`에 pem-server 서비스 추가

#### 5.2 독립적인 pem-server 컨테이너 테스트
```bash
# pem-server 컨테이너 실행
docker-compose -f docker-compose.sam6d.yml up -d pem-server

# 로그 확인
docker-compose -f docker-compose.sam6d.yml logs -f pem-server

# 컨테이너 내부에서 테스트
docker exec -it pem-server bash
curl http://localhost:8003/health
curl http://localhost:8003/api/v1/status
```

#### 5.3 외부에서 접근 테스트
```bash
# 호스트에서 접근 테스트
curl http://localhost:8003/health
curl http://localhost:8003/api/v1/status

# 포즈 추정 테스트
curl -X POST "http://localhost:8003/api/v1/pose_estimation" \
  -H "Content-Type: application/json" \
  -d @sample_data.json
```

#### 5.4 성능 테스트
```bash
# 동시 요청 테스트
for i in {1..3}; do
  curl -X POST "http://localhost:8003/api/v1/pose_estimation" \
    -H "Content-Type: application/json" \
    -d @sample_data.json &
done
wait
```

#### 5.5 성공 기준
- ✅ pem-server 컨테이너가 정상적으로 시작됨
- ✅ 모든 API 엔드포인트가 정상적으로 동작함
- ✅ PEM 모델 로딩이 정상적으로 완료됨
- ✅ 포즈 추정 기능이 정상적으로 동작함
- ✅ 외부에서 접근 가능함
- ✅ 동시 요청 처리가 가능함

---

## 버그 잡기 전략

### 1. 로그 기반 디버깅
- 각 단계마다 상세한 로그 출력
- 에러 발생 시 구체적인 에러 메시지 제공
- 성능 메트릭 수집 (로딩 시간, 추론 시간)

### 2. 단계별 검증
- 각 Phase 완료 후 반드시 테스트 실행
- 실패 시 이전 단계로 돌아가서 문제 해결
- 성공 기준을 만족할 때까지 다음 단계로 진행하지 않음

### 3. 점진적 복잡성 증가
- Phase 1: 가장 기본적인 기능부터
- Phase 2: PEM 모델 로딩 (가장 복잡한 부분)
- Phase 3: 포즈 추정 기능 (비즈니스 로직)
- Phase 4: ISM 연동 (통합 테스트)
- Phase 5: 배포 환경 (운영 환경)

### 4. 테스트 데이터 활용
- 기존 SAM-6D 예제 데이터 활용
- ISM Server 결과와 연동 테스트
- 다양한 입력 케이스 테스트

---

## 예상 문제점 및 해결 방안

### 1. PEM 모델 로딩 실패
**문제**: GPU 메모리 부족, 모델 파일 경로 오류, PointNet2 CUDA 확장 실패
**해결**: 메모리 사용량 모니터링, 경로 검증 로직 추가, CUDA 환경 확인

### 2. 포인트 클라우드 처리 실패
**문제**: 깊이 이미지 형식 오류, 마스크 처리 실패
**해결**: 이미지 형식 검증, 마스크 전처리 로직 강화

### 3. 포즈 추정 성능 문제
**문제**: 추론 시간 과다, 메모리 누수, 정확도 저하
**해결**: 성능 프로파일링, 메모리 모니터링, 모델 최적화

### 4. ISM Server 연동 문제
**문제**: 네트워크 통신 실패, 데이터 형식 불일치
**해결**: 연결 상태 확인, 데이터 스키마 검증

### 5. Docker 환경 문제
**문제**: 볼륨 마운트 실패, 환경 변수 설정 오류, 포트 충돌
**해결**: 볼륨 경로 검증, 환경 변수 확인, 포트 매핑 확인

---

## 추가 고려사항

### 1. ISM Server 의존성
- PEM Server는 ISM Server의 결과에 의존
- ISM Server가 실행되지 않으면 포즈 추정 불가
- 독립적인 테스트를 위한 모의 데이터 필요

### 2. 메모리 관리
- ISM과 PEM 모델을 동시에 로딩하면 메모리 사용량 증가
- 모델별 메모리 사용량 모니터링 필요
- 필요시 모델 언로딩/로딩 전략 고려

### 3. 성능 최적화
- 포인트 클라우드 전처리 최적화
- 배치 처리 지원 고려
- GPU 메모리 효율성 개선

이 계획을 따라 단계별로 구현하면 안정적이고 확장 가능한 PEM 서버를 구축할 수 있습니다.
